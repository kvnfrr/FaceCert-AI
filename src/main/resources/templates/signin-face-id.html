<!DOCTYPE html>
<html xmlns:th="http://www.thymeleaf.org">
<head>
    <title>Sign In with Face ID</title>
    <!-- Include Face API library -->
    <script src="https://cdn.jsdelivr.net/npm/@vladmandic/face-api/dist/face-api.min.js"></script>
    <!-- Include IndexedDB script -->
    <script src="/static/js/indexeddb.js" defer></script>
</head>
<body>
<h1>Sign In with Face ID</h1>
<p>Align your face in the camera view to authenticate.</p>

<!-- Video feed for camera -->
<video id="camera" autoplay playsinline></video>

<!-- Hidden canvas for capturing the frame -->
<canvas id="canvas" style="display: none;"></canvas>

<!-- Status Message -->
<p id="status">Initializing face recognition...</p>

<script>
    const video = document.getElementById('camera');
    const canvas = document.getElementById('canvas');
    const status = document.getElementById('status');

    // Start the camera stream
    navigator.mediaDevices.getUserMedia({ video: true })
        .then(stream => {
            video.srcObject = stream;
        })
        .catch(err => console.error("Camera access denied:", err));

    // Load face-api models
    Promise.all([
        faceapi.nets.ssdMobilenetv1.loadFromUri('/static/models'),
        faceapi.nets.faceLandmark68Net.loadFromUri('/static/models'),
        faceapi.nets.faceRecognitionNet.loadFromUri('/static/models')
    ]).then(() => {
        status.innerText = "Face recognition models loaded. Align your face to start.";
    }).catch(err => console.error("Error loading models:", err));

    // Perform face detection and descriptor matching
    video.addEventListener('play', async () => {
        const canvasContext = canvas.getContext('2d');
        canvas.width = video.videoWidth;
        canvas.height = video.videoHeight;

        status.innerText = "Align your face. Authenticating...";

        const interval = setInterval(async () => {
            const detections = await faceapi
                .detectAllFaces(video, new faceapi.SsdMobilenetv1Options())
                .withFaceLandmarks()
                .withFaceDescriptors();

            if (detections.length > 0) {
                clearInterval(interval);

                const detectedDescriptor = detections[0].descriptor;

                // Fetch all stored face descriptors from IndexedDB
                fetchAllFromIndexedDB((storedData) => {
                    const labeledDescriptors = storedData.map((data) =>
                        new faceapi.LabeledFaceDescriptors("User", [new Float32Array(data.content)])
                    );

                    const faceMatcher = new faceapi.FaceMatcher(labeledDescriptors);
                    const bestMatch = faceMatcher.findBestMatch(detectedDescriptor);

                    if (bestMatch.label === "User" && bestMatch.distance < 0.6) {
                        status.innerText = "Authentication successful! Welcome.";
                        alert("Authentication successful!");
                    } else {
                        status.innerText = "Authentication failed. No match found.";
                        alert("Authentication failed. Please try again.");
                    }
                });
            }
        }, 1000); // Run face detection every second
    });
</script>
</body>
</html>
